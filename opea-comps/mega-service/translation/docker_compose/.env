# Set default values
host_ip="${host_ip:-localhost}"

NETW_PREFIX="10.5.0"
OPEA_NETW_SUBNET=10.5.0.0/16
OPEA_NETW_GATEWAY=10.5.0.1
LLM_HOST_IP=${NETW_PREFIX}.2
LLM_SERVICE_HOST_IP=${NETW_PREFIX}.3
MEGA_SERVICE_HOST_IP=${NETW_PREFIX}.4
FRONTEND_SERVICE_IP=${NETW_PREFIX}.5
FRONTEND_NGINX_IP=${NETW_PREFIX}.6

LLM_COMPONENT_NAME="OpeaTextGenService"
LLM_MODEL_ID="llama3.1"
LLM_ENDPOINT_PORT="8008"
LLM_ENDPOINT_EXT_PORT="11434"
LLM_ENDPOINT="http://${LLM_HOST_IP}:${LLM_ENDPOINT_EXT_PORT}"
TGI_LLM_ENDPOINT=${LLM_ENDPOINT}
HUGGINGFACEHUB_API_TOKEN=${hf_token}
MEGA_SERVICE_HOST_IP=${MEGA_SERVICE_HOST_IP}
LLM_SERVICE_HOST_IP=${LLM_SERVICE_HOST_IP}
BACKEND_SERVICE_ENDPOINT="http://${host_ip}:8888/v1/translation"
NGINX_PORT=8080
FRONTEND_SERVICE_IP=${FRONTEND_SERVICE_IP}
FRONTEND_SERVICE_PORT=5173
BACKEND_SERVICE_NAME=translation
BACKEND_SERVICE_IP=${MEGA_SERVICE_HOST_IP}
BACKEND_SERVICE_PORT=8888